{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Emotional Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default backend: module://matplotlib_inline.backend_inline\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import scipy.sparse\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib, mplcairo\n",
    "import pickle\n",
    "print('Default backend: ' + matplotlib.get_backend()) \n",
    "#matplotlib.use(\"module://mplcairo.macosx\")\n",
    "#print('Backend is now ' + matplotlib.get_backend())\n",
    "sns.set()\n",
    "\n",
    "path_root = \"/Users/atanaltay/Documents/Research/inwork/marketing_emotions/codes/data/all_marketing_data/\"\n",
    "groupsAndCountsPath = path_root + \"emoticon_analysis/tr_emoticon_groups_and_counts.csv\"\n",
    "emojisPath = path_root + \"emoticon_analysis/emojis.csv\"\n",
    "path_in = path_root+ \"tr_emoanalysis.parquet\"\n",
    "path_in_en= path_root + \"en_emoanalysis.parquet\"\n",
    "#Existing emojis\n",
    "groupsAndCountsDfEn = pd.read_csv(path_root + \"emoticon_analysis/en_emoticon_groups_and_counts.csv\")\n",
    "groupsAndCountsDfTr = pd.read_csv(groupsAndCountsPath)\n",
    "#Emoji codes\n",
    "emojisdf = pd.read_csv(emojisPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cooccurrance calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/atanaltay/opt/anaconda3/lib/python3.7/site-packages/scipy/sparse/_index.py:125: SparseEfficiencyWarning: Changing the sparsity structure of a csc_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    }
   ],
   "source": [
    "#Prepare vocabulary\n",
    "dfTr = pd.read_parquet(path_in,columns=[\"text_stemmed\"])\n",
    "\n",
    "#Turkish\n",
    "tr_anger_seeds = pickle.load( open( path_root + \"seeds/tr90/anger\", \"rb\" ) )\n",
    "tr_happy_seeds = pickle.load( open( path_root + \"seeds/tr90/happy\", \"rb\" ) )\n",
    "tr_sad_seeds = pickle.load( open( path_root + \"seeds/tr90/sad\", \"rb\" ) )\n",
    "tr_fear_seeds = pickle.load( open( path_root + \"seeds/tr90/fear\", \"rb\" ) )\n",
    "tr_surprise_seeds = pickle.load( open( path_root + \"seeds/tr90/surprise\", \"rb\" ) )\n",
    "tr_disgust_seeds = pickle.load( open( path_root + \"seeds/tr90/disgust\", \"rb\" ) )\n",
    "tr_seeds_dict = {\"anger\":tr_anger_seeds,\"happy\":tr_happy_seeds,\"sad\":tr_sad_seeds,\"fear\":tr_fear_seeds,\"surprise\":tr_surprise_seeds,\"disgust\":tr_disgust_seeds}\n",
    "\n",
    "tr_emos = groupsAndCountsDfTr.copy()\n",
    "tr_emos.emoticon = tr_emos.emoticon.str.strip(\"_\")\n",
    "tr_emos.index =tr_emos.emoticon\n",
    "\n",
    "vocab_list = []\n",
    "for key, seeds in tr_seeds_dict.items():\n",
    "      vocab_list.extend(seeds)\n",
    "\n",
    "idx_max_seeds = len(vocab_list)-1\n",
    "\n",
    "#check duplicates and remove from emo\n",
    "set_emos = set(tr_emos.emoticon.to_list())\n",
    "\n",
    "for word in vocab_list:\n",
    "    for emo in tr_emos.emoticon.to_list():\n",
    "        if word == emo:\n",
    "            set_emos.remove(emo)\n",
    "\n",
    "\n",
    "vocab_list.extend(set_emos)\n",
    "\n",
    "vocab_dict = dict()\n",
    "\n",
    "for idx in range(len(vocab_list)):\n",
    "    vocab_dict[vocab_list[idx]] = idx\n",
    "\n",
    "vectorizer = CountVectorizer(vocabulary=vocab_dict,lowercase=False)\n",
    "X = vectorizer.fit_transform(dfTr.text_stemmed)\n",
    "Xc = (X.T * X)\n",
    "Xc.setdiag(0)\n",
    "\n",
    "cofreqs_tr = pd.DataFrame(Xc.toarray(),columns=vectorizer.get_feature_names_out(),index=vectorizer.get_feature_names_out())\n",
    "cofreqs_tr = cofreqs_tr.iloc[idx_max_seeds+1:len(vectorizer.get_feature_names_out()),0:idx_max_seeds+1]\n",
    "\n",
    "#importance calculation\n",
    "all_sum = cofreqs_tr.sum(axis=1)\n",
    "importance_df_tr = pd.DataFrame(index=cofreqs_tr.index)\n",
    "#importance_df_tr = importance_df.join(tr_emos['count'])\n",
    "\n",
    "for key, seeds in tr_seeds_dict.items():\n",
    "    emotion_sum = cofreqs_tr.loc[:,seeds].sum(axis=1)\n",
    "    sub_score = emotion_sum/all_sum\n",
    "    #emotion_score = sub_score*np.log10(tr_emos['count'])\n",
    "    df_emotion_sum = pd.DataFrame(sub_score,columns=[key])\n",
    "    importance_df_tr = importance_df_tr.join(df_emotion_sum,how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cofreqs_tr.to_csv(path_root+\"selected_emoticons/tr90/cofreq_tr.csv\",index=True,header=True,index_label=\"idx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df_tr.to_csv(path_root +\"selected_emoticons/tr90/relevance_tr.csv\",index_label=\"idx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare vocabulary\n",
    "\n",
    "#English\n",
    "\n",
    "dfEn = pd.read_parquet(path_in_en,columns=[\"text_stemmed\"])\n",
    "\n",
    "#Prepare vocabulary\n",
    "\n",
    "en_anger_seeds = pickle.load( open( path_root + \"seeds/en90/anger\", \"rb\" ))\n",
    "en_happy_seeds = pickle.load( open( path_root + \"seeds/en90/happy\", \"rb\" ))\n",
    "en_sad_seeds = pickle.load( open( path_root + \"seeds/en90/sad\", \"rb\" ) )\n",
    "en_fear_seeds = pickle.load( open( path_root + \"seeds/en90/fear\", \"rb\" ) )\n",
    "en_surprise_seeds = pickle.load( open( path_root + \"seeds/en90/surprise\", \"rb\" ) )\n",
    "en_disgust_seeds = pickle.load( open( path_root + \"seeds/en90/disgust\", \"rb\" ) )\n",
    "en_seeds_dict = {\"anger\":en_anger_seeds,\"happy\":en_happy_seeds,\"sad\":en_sad_seeds,\"fear\":en_fear_seeds,\"surprise\":en_surprise_seeds,\"disgust\":en_disgust_seeds}\n",
    "\n",
    "en_emos = groupsAndCountsDfEn.copy()\n",
    "en_emos.emoticon = en_emos.emoticon.str.strip(\"_\")\n",
    "en_emos.index =en_emos.emoticon\n",
    "\n",
    "vocab_list = []\n",
    "for key, seeds in en_seeds_dict.items():\n",
    "      vocab_list.extend(seeds)\n",
    "\n",
    "idx_max_seeds = len(vocab_list)-1\n",
    "\n",
    "#check duplicates and remove from emo\n",
    "set_emos = set(en_emos.emoticon.to_list())\n",
    "\n",
    "for word in vocab_list:\n",
    "    for emo in en_emos.emoticon.to_list():\n",
    "        if word == emo:\n",
    "            set_emos.remove(emo)\n",
    "\n",
    "\n",
    "vocab_list.extend(set_emos)\n",
    "\n",
    "vocab_dict = dict()\n",
    "\n",
    "for idx in range(len(vocab_list)):\n",
    "    vocab_dict[vocab_list[idx]] = idx\n",
    "\n",
    "vectorizer = CountVectorizer(vocabulary=vocab_dict,lowercase=False)\n",
    "X = vectorizer.fit_transform(dfEn.text_stemmed)\n",
    "Xc = (X.T*X)\n",
    "Xc.setdiag(0)\n",
    "\n",
    "cofreqs_En = pd.DataFrame(Xc.toarray(),columns=vectorizer.get_feature_names_out(),index=vectorizer.get_feature_names_out())\n",
    "cofreqs_En = cofreqs_En.iloc[idx_max_seeds+1:len(vectorizer.get_feature_names_out()),0:idx_max_seeds+1]\n",
    "\n",
    "#importance calculation\n",
    "all_sum = cofreqs_En.sum(axis=1)\n",
    "importance_df_en = pd.DataFrame(index=cofreqs_En.index)\n",
    "#importance_df = importance_df.join(en_emos['count'])\n",
    "\n",
    "for key, seeds in en_seeds_dict.items():\n",
    "    \n",
    "    emotion_sum = cofreqs_En.loc[:,seeds].sum(axis=1)\n",
    "    sub_score = emotion_sum/all_sum\n",
    "    #emotion_score = sub_score*np.log10(en_emos['count'])\n",
    "    df_emotion_sum = pd.DataFrame(sub_score,columns=[key])\n",
    "    importance_df_en = importance_df_en.join(df_emotion_sum,how='left')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cofreqs_En.to_csv(path_root+\"selected_emoticons/en90/cofreq_en.csv\",index=True,header=True,index_label=\"idx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df_en.to_csv(path_root +\"selected_emoticons/en90/relevance_en.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From here on we may load data without re counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df_en = pd.read_csv(path_root +\"selected_emoticons/en90/relevance_en.csv\",index_col=\"idx\")\n",
    "#importance_df_tr = pd.read_csv(path_root +\"selected_emoticons/tr90/relevance_tr.csv\",index_col=\"idx\")\n",
    "cofreqs_En = pd.read_csv(path_root+\"selected_emoticons/en90/cofreq_en.csv\",index_col=\"idx\")\n",
    "#cofreqs_Tr = pd.read_csv(path_root+\"selected_emoticons/tr90/cofreq_tr.csv\",index_col=\"idx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cscPathTr = path_root + \"emoticon_analysis/count_matrices/tr/csc_count.npz\"\n",
    "#featuresPathTr = path_root + \"emoticon_analysis/count_matrices/tr/feature_names.npy\"\n",
    "\n",
    "cscPathEn = path_root + \"emoticon_analysis/count_matrices/en/csc_count.npz\"\n",
    "featuresPathEn = path_root + \"emoticon_analysis/count_matrices/en/feature_names.npy\"\n",
    "\n",
    "#cscCountsMatrixTr = scipy.sparse.load_npz(cscPathTr)\n",
    "#featureNamesArrayTr = np.load(featuresPathTr,allow_pickle=True)\n",
    "\n",
    "cscCountsMatrixEn = scipy.sparse.load_npz(cscPathEn)\n",
    "featureNamesArrayEn = np.load(featuresPathEn,allow_pickle=True)\n",
    "\n",
    "#dfTr = pd.read_parquet(path_in,columns=[\"id\",\"created_at\",\"company\",\"type\",\"industry\",\"gender\"])\n",
    "#dfEn = pd.read_parquet(path_in_en,columns=[\"id\",\"created_at\",\"company\",\"type\",\"industry\",\"gender\"])\n",
    "\n",
    "#countsTr = pd.DataFrame(cscCountsMatrixTr.sum(axis=0),columns=featureNamesArrayTr).T.rename(columns={0:\"cnt\"})\n",
    "countsEn = pd.DataFrame(cscCountsMatrixEn.sum(axis=0),columns=featureNamesArrayEn).T.rename(columns={0:\"cnt\"})\n",
    "\n",
    "# selecting top 75%\n",
    "\n",
    "#countsTr = countsTr[countsTr.cnt>16]\n",
    "countsEn = countsEn[countsEn.cnt>110]\n",
    "#countsTr.index = countsTr.index.str.strip(\"_\")\n",
    "countsEn.index = countsEn.index.str.strip(\"_\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importance_frequent_tr = importance_df_tr[importance_df_tr.index.isin(countsTr.index)]\n",
    "importance_frequent_en = importance_df_en[importance_df_en.index.isin(countsEn.index)]\n",
    "\n",
    "#importance_frequent_tr =importance_frequent_tr.merge(countsTr, left_index=True,right_on=countsTr.index)\n",
    "importance_frequent_en =importance_frequent_en.merge(countsEn, left_index=True,right_on=countsEn.index)\n",
    "\n",
    "importance_frequent_en.dropna(how=\"any\",inplace=True)\n",
    "#importance_frequent_tr.dropna(how=\"any\",inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupsAndCountsDfEn.emoticon = groupsAndCountsDfEn.emoticon.str.strip(\"_\")\n",
    "groupsAndCountsDfTr.emoticon = groupsAndCountsDfTr.emoticon.str.strip(\"_\")\n",
    "\n",
    "dftoplot_en = importance_frequent_en.sort_values(by=\"cnt\",ascending=False).head(40)\n",
    "dftoplot_tr = importance_frequent_tr.sort_values(by=\"cnt\",ascending=False).head(40)\n",
    "\n",
    "dftoplot_en = dftoplot_en.merge(groupsAndCountsDfEn,left_index=True,right_on=\"emoticon\")\n",
    "dftoplot_tr = dftoplot_tr.merge(groupsAndCountsDfTr,left_index=True,right_on=\"emoticon\")\n",
    "\n",
    "dftoplot_en.drop(columns=[\"key_0\",\"cnt_x\",\"cnt_y\"],inplace=True)\n",
    "dftoplot_tr.drop(columns=[\"key_0\",\"cnt_x\",\"cnt_y\"],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftoplot_en_new = dftoplot_en[[\"anger\",\"happy\",\"sad\",\"fear\",\"surprise\",\"disgust\",\"emoji\"]]\n",
    "dftoplot_en_new.index = dftoplot_en_new.emoji\n",
    "\n",
    "dftoplot_tr_new = dftoplot_tr[[\"anger\",\"happy\",\"sad\",\"fear\",\"surprise\",\"disgust\",\"emoji\"]]\n",
    "dftoplot_tr_new.index = dftoplot_tr_new.emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default backend: module://mplcairo.macosx\n",
      "Backend is now module://mplcairo.macosx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/atanaltay/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib, mplcairo\n",
    "from matplotlib.font_manager import FontProperties\n",
    "print('Default backend: ' + matplotlib.get_backend()) \n",
    "matplotlib.use(\"module://mplcairo.macosx\")\n",
    "print('Backend is now ' + matplotlib.get_backend())\n",
    "\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(8,6))\n",
    "# Load Apple Color Emoji font \n",
    "prop = FontProperties(fname='/System/Library/Fonts/Apple Color Emoji.ttc',size=16)\n",
    "ax.set_ylabel(\"Relevance\")\n",
    "ax.set_title(\"Top 40 Emoticon Distributions by Emotion - English\")\n",
    "ax.set_xticklabels(labels=dftoplot_en_new.index.tolist(),fontproperties=prop)\n",
    "dftoplot_en_new.plot.bar(stacked=True,ax=ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/atanaltay/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Top 40 Emoticon Distributions by Emotion - Turkish'}, xlabel='emoji', ylabel='Relevance'>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig,ax = plt.subplots(figsize=(8,6))\n",
    "# Load Apple Color Emoji font \n",
    "prop = FontProperties(fname='/System/Library/Fonts/Apple Color Emoji.ttc',size=16)\n",
    "ax.set_ylabel(\"Relevance\")\n",
    "ax.set_title(\"Top 40 Emoticon Distributions by Emotion - Turkish\")\n",
    "ax.set_xticklabels(labels=dftoplot_tr_new.index.tolist(),fontproperties=prop)\n",
    "dftoplot_tr_new.plot.bar(stacked=True,ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commons = set(importance_frequent_en.index.to_list()).intersection(set(importance_frequent_tr.index.to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commons_tr = importance_frequent_tr[importance_frequent_tr.index.isin(commons)]\n",
    "commons_en = importance_frequent_en[importance_frequent_en.index.isin(commons)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_0</th>\n",
       "      <th>anger</th>\n",
       "      <th>happy</th>\n",
       "      <th>sad</th>\n",
       "      <th>fear</th>\n",
       "      <th>surprise</th>\n",
       "      <th>disgust</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sneezing_face</th>\n",
       "      <td>sneezing_face</td>\n",
       "      <td>0.195584</td>\n",
       "      <td>0.320189</td>\n",
       "      <td>0.170347</td>\n",
       "      <td>0.126183</td>\n",
       "      <td>0.123028</td>\n",
       "      <td>0.064669</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crescent_moon</th>\n",
       "      <td>crescent_moon</td>\n",
       "      <td>0.204545</td>\n",
       "      <td>0.204545</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dashing_away</th>\n",
       "      <td>dashing_away</td>\n",
       "      <td>0.189573</td>\n",
       "      <td>0.317536</td>\n",
       "      <td>0.090047</td>\n",
       "      <td>0.113744</td>\n",
       "      <td>0.175355</td>\n",
       "      <td>0.113744</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raised_hand</th>\n",
       "      <td>raised_hand</td>\n",
       "      <td>0.195251</td>\n",
       "      <td>0.278364</td>\n",
       "      <td>0.124011</td>\n",
       "      <td>0.182058</td>\n",
       "      <td>0.124011</td>\n",
       "      <td>0.096306</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>face_with_open_mouth</th>\n",
       "      <td>face_with_open_mouth</td>\n",
       "      <td>0.145161</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.119355</td>\n",
       "      <td>0.158065</td>\n",
       "      <td>0.170968</td>\n",
       "      <td>0.116129</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tulip</th>\n",
       "      <td>tulip</td>\n",
       "      <td>0.121622</td>\n",
       "      <td>0.347973</td>\n",
       "      <td>0.118243</td>\n",
       "      <td>0.111486</td>\n",
       "      <td>0.148649</td>\n",
       "      <td>0.152027</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shopping_cart</th>\n",
       "      <td>shopping_cart</td>\n",
       "      <td>0.131274</td>\n",
       "      <td>0.418919</td>\n",
       "      <td>0.179537</td>\n",
       "      <td>0.038610</td>\n",
       "      <td>0.144788</td>\n",
       "      <td>0.086873</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crossed_swords</th>\n",
       "      <td>crossed_swords</td>\n",
       "      <td>0.176991</td>\n",
       "      <td>0.256637</td>\n",
       "      <td>0.168142</td>\n",
       "      <td>0.115044</td>\n",
       "      <td>0.221239</td>\n",
       "      <td>0.061947</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cold_face</th>\n",
       "      <td>cold_face</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>0.122951</td>\n",
       "      <td>0.139344</td>\n",
       "      <td>0.131148</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beating_heart</th>\n",
       "      <td>beating_heart</td>\n",
       "      <td>0.162420</td>\n",
       "      <td>0.391720</td>\n",
       "      <td>0.116242</td>\n",
       "      <td>0.106688</td>\n",
       "      <td>0.135350</td>\n",
       "      <td>0.087580</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>417 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     key_0     anger     happy       sad  \\\n",
       "sneezing_face                sneezing_face  0.195584  0.320189  0.170347   \n",
       "crescent_moon                crescent_moon  0.204545  0.204545  0.083333   \n",
       "dashing_away                  dashing_away  0.189573  0.317536  0.090047   \n",
       "raised_hand                    raised_hand  0.195251  0.278364  0.124011   \n",
       "face_with_open_mouth  face_with_open_mouth  0.145161  0.290323  0.119355   \n",
       "...                                    ...       ...       ...       ...   \n",
       "tulip                                tulip  0.121622  0.347973  0.118243   \n",
       "shopping_cart                shopping_cart  0.131274  0.418919  0.179537   \n",
       "crossed_swords              crossed_swords  0.176991  0.256637  0.168142   \n",
       "cold_face                        cold_face  0.262295  0.245902  0.122951   \n",
       "beating_heart                beating_heart  0.162420  0.391720  0.116242   \n",
       "\n",
       "                          fear  surprise   disgust  cnt  \n",
       "sneezing_face         0.126183  0.123028  0.064669  181  \n",
       "crescent_moon         0.272727  0.151515  0.083333   39  \n",
       "dashing_away          0.113744  0.175355  0.113744   35  \n",
       "raised_hand           0.182058  0.124011  0.096306  174  \n",
       "face_with_open_mouth  0.158065  0.170968  0.116129  104  \n",
       "...                        ...       ...       ...  ...  \n",
       "tulip                 0.111486  0.148649  0.152027   71  \n",
       "shopping_cart         0.038610  0.144788  0.086873   85  \n",
       "crossed_swords        0.115044  0.221239  0.061947   47  \n",
       "cold_face             0.139344  0.131148  0.098361   37  \n",
       "beating_heart         0.106688  0.135350  0.087580  244  \n",
       "\n",
       "[417 rows x 8 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commons_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commons_en = commons_en.merge(groupsAndCountsDfEn,left_index=True,right_on=\"emoticon\")\n",
    "commons_tr = commons_tr.merge(groupsAndCountsDfTr,left_index=True,right_on=\"emoticon\")\n",
    "\n",
    "commons_en.drop(columns=[\"key_0\",\"cnt_x\",\"cnt_y\"],inplace=True)\n",
    "commons_tr.drop(columns=[\"key_0\",\"cnt_x\",\"cnt_y\"],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commons_tr.index = commons_tr.emoticon\n",
    "commons_en.index = commons_en.emoticon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "distances = dict()\n",
    "\n",
    "for idx, row in commons_en.iterrows():\n",
    "    dist1 = commons_tr.loc[idx,[\"anger\",\"disgust\",\"fear\",\"happy\",\"sad\",\"surprise\"]].to_numpy().astype('float64')\n",
    "    dist2 = commons_en.loc[idx,[\"anger\",\"disgust\",\"fear\",\"happy\",\"sad\",\"surprise\"]].to_numpy().astype('float64')\n",
    "    distance_jensen= distance.jensenshannon(dist1,dist2)\n",
    "    distances[row.emoji] = distance_jensen\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfToPLotdist = pd.DataFrame(distances.values(),index=distances.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfToPLotdist.rename(columns={0:\"distance\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfToPLotdist.sort_values(by=\"distance\").head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/atanaltay/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Common Emoticons - Distance'}, ylabel='Distance'>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "fig,ax = plt.subplots(figsize=(8,6))\n",
    "# Load Apple Color Emoji font \n",
    "prop = FontProperties(fname='/System/Library/Fonts/Apple Color Emoji.ttc',size=16)\n",
    "ax.set_ylabel(\"Distance\")\n",
    "ax.set_title(\"Common Emoticons - Distance\")\n",
    "\n",
    "dfff = dfToPLotdist.sort_values(by=\"distance\").head(50)\n",
    "\n",
    "ax.set_xticklabels(labels=dfff.index.tolist(),fontproperties=prop)\n",
    "dfff.plot.bar(stacked=True,ax=ax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
